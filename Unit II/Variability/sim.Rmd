---
title: "Analysis of Simulated Data with OPG Algorithm"
output:
  pdf_document:
    number_sections: true
geometry: "left=0.5cm,right=0.5cm,top=0.5cm,bottom=1.5cm"
---

``` {r}
library(ggplot2, quietly = TRUE)
library(dplyr, quietly = TRUE)
library(Rcpp, quietly = TRUE)
sourceCpp("../../src/mave/02_Rcpp/mave.cpp")
source("../../src/mave/02_Rcpp/mave.R")

# Set verbose to TRUE for lots of logging
verbose <- FALSE
```

# Generate data
``` {r}
set.seed(1234)
n <- 1000
X <- cbind(
	runif(n, -4, 4),
	rnorm(n),
	rnorm(n, sd = 10)
)
B.true <- as.matrix(normalize(c(1, 0.1, 0)))
rx.true <- X %*% B.true
sigma.true <- 0.1
f.true <- function(x) { 1 / (1 + x^2) }
y <- rnorm(n, f.true(rx.true), sigma.true)

ggplot(data.frame(rx.true, y), aes(rx.true, y)) +
    geom_point() +
    stat_function(fun = f.true, col = "red", lwd = 1.1)
```

# Arbitrary bandwidth selection
The choice `h.arb = 0.1` leads to overfitting.
``` {r}
h.arb <- 0.1
fit.out <- opg(y, X, h = h.arb, d = 1)
pred.out <- predict(fit.out, X.new = X)
obj.out <- mave.obj(y, X, B = fit.out$B, h = h.arb)

# Plot predictions
ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point() +
    stat_function(fun = identity, lwd = 1.1, color = "red")

# Plot reduction versus predictions
rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point() +
    stat_function(fun = f.true, lwd = 1.1, color = "red")
```

The choice `h.arb = 4` leads to oversmoothing.
``` {r}
h.arb <- 4
fit.out <- opg(y, X, h = h.arb, d = 1)
pred.out <- predict(fit.out, X.new = X)
obj.out <- mave.obj(y, X, B = fit.out$B, h = h.arb)

# Plot predictions
ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point() +
    stat_function(fun = identity, lwd = 1.1, color = "red")

# Plot reduction versus predictions
rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point() +
    stat_function(fun = f.true, lwd = 1.1, color = "red")
```

The choice `h.arb = 0.5` gives a reasonable result.
``` {r}
h.arb <- 0.5
fit.out <- opg(y, X, h = h.arb, d = 1)
pred.out <- predict(fit.out, X.new = X)
obj.out <- mave.obj(y, X, B = fit.out$B, h = h.arb)

# Plot predictions
ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point() +
    stat_function(fun = identity, lwd = 1.1, color = "red")

# Plot reduction versus predictions
rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point() +
    stat_function(fun = f.true, lwd = 1.1, color = "red")
```

# Training, validation, and test sets
First try taking training and validation sets to be the same. Do we overfit?
``` {r}
set.seed(1234)
idx.train <- sample(1:n, size = ceiling(0.8*n), replace = FALSE)
idx.test <- setdiff(1:n, idx.train)
set <- ifelse(1:n %in% idx.train, "train", "test")
color <- ifelse(set == "train", "blue", "darkorange")

h.levels <- seq(0.1, 4, length = 100)
na <- rep(NA, length(h.levels))
tab <- data.frame(h = h.levels, mape.train = na, mape.test = na)

for (idx1 in 1:length(h.levels)) {
	h <- h.levels[idx1]
	fit.out <- opg(y[idx.train], X[idx.train,], h = h, d = 1, use.cpp = TRUE)
	pred.out <- predict(fit.out, X.new = X, use.cpp = TRUE)
	obj.out <- mave.obj(y, X, B = fit.out$B, h = h, idx.train = idx.train, idx.val = 1:n)

	tab$mape.train[idx1] <- mean(abs(y[idx.train] - pred.out[idx.train]))
	tab$mape.test[idx1] <- mean(abs(y[idx.test] - pred.out[idx.test]))

	if (verbose) {
		printf("h[%d]: %0.4f\n", idx1, h)
		printf("  train MAPE: %0.4f\n", tab$mape.train[idx1])
		printf("  test MAPE: %0.4f\n", tab$mape.test[idx1])
	}
}
# print(tab)

ggplot(tab) +
	geom_line(aes(h, mape.train), lty = 2, col = "red", lwd = 1.1) +
	geom_line(aes(h, mape.test), lwd = 1.1) +
	ylab("MAPE")

h.train <- h.levels[which.min(tab$mape.train)]
h.test <- h.levels[which.min(tab$mape.test)]

# Check results for model selected by training data
fit.out <- opg(y[idx.train], X[idx.train,], h = h.train, d = 1)
print(fit.out)
pred.out <- predict(fit.out, X.new = X)

ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point(color = color) +
    stat_function(fun = identity, lwd = 1.1)

rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point(color = color) +
    stat_function(fun = f.true, lwd = 1.1)

# Check results for best model according to test data
fit.out <- opg(y[idx.train], X[idx.train,], h = h.test, d = 1)
print(fit.out)
pred.out <- predict(fit.out, X.new = X)

ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point(color = color) +
    stat_function(fun = identity, lwd = 1.1)

rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point(color = color) +
    stat_function(fun = f.true, lwd = 1.1)
```

Now take training and validation sets to be different.

``` {r}
set.seed(1234)
idx.train <- sample(1:n, size = ceiling(0.8*n))
idx.val <- sample(setdiff(1:n, idx.train), size = ceiling(0.1*n))
idx.test <- setdiff(1:n, union(idx.train, idx.val))

set <- rep(NA, n)
set[idx.train] <- "train"
set[idx.val] <- "val"
set[idx.test] <- "test"

color <- rep(NA, n)
color[set == "train"] <- "blue"
color[set == "val"] <- "green"
color[set == "test"] <- "darkorange"

h.levels <- seq(0.1, 4, length = 100)
na <- rep(NA, length(h.levels))
tab <- data.frame(h = h.levels, mape.val = na, mape.test = na)

for (idx1 in 1:length(h.levels)) {
	h <- h.levels[idx1]
	fit.out <- opg(y[idx.train], X[idx.train,], h = h, d = 1)
	pred.out <- predict(fit.out, X.new = X)

	tab$mape.val[idx1] <- mean(abs(y[idx.val] - pred.out[idx.val]))
	tab$mape.test[idx1] <- mean(abs(y[idx.test] - pred.out[idx.test]))

	if (verbose) {
		printf("h[%d]: %0.4f\n", idx1, h)
		printf("  val MAPE: %0.4f\n", tab$mape.val[idx1])
		printf("  test MAPE: %0.4f\n", tab$mape.test[idx1])
	}
}
# print(tab)

ggplot(tab) +
	geom_line(aes(h, mape.val), lty = 2, col = "red", lwd = 1.1) +
	geom_line(aes(h, mape.test), lwd = 1.1) +
	ylab("MAPE")

h.val <- h.levels[which.min(tab$mape.val)]
h.test <- h.levels[which.min(tab$mape.test)]

# Check results for model selected by training/validation
fit.out <- opg(y[-idx.test], X[-idx.test,], h = h.val, d = 1)
print(fit.out)
pred.out <- predict(fit.out, X.new = X)

ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point(color = color) +
    stat_function(fun = identity, lwd = 1.1)

rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point(color = color) +
    stat_function(fun = f.true, lwd = 1.1)

# Check results for best model according to test data
fit.out <- opg(y[-idx.test], X[-idx.test,], h = h.test, d = 1)
print(fit.out)
pred.out <- predict(fit.out, X.new = X)

ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point(color = color) +
    stat_function(fun = identity)

rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point(color = color) +
    stat_function(fun = f.true, lwd = 1.1)
```

# Cross-validation
``` {r}
set.seed(1234)
idx.cv <- sample(1:n, size = ceiling(0.8*n), replace = FALSE)
idx.test <- setdiff(1:n, idx.cv)
set <- ifelse(1:n %in% idx.cv, "cv", "test")

color <- rep(NA, n)
color[set == "cv"] <- "blue"
color[set == "test"] <- "darkorange"

# Take a sample of the obs as a training sample
n.cv <- length(idx.cv)

# Set up folds for K-fold cross-validation
K <- 5
fold.grp <- sample((1:n.cv - 1) %% K + 1)
folds <- split(1:n.cv, f = fold.grp)

h.levels <- seq(0.1, 4, length = 100)
na <- rep(NA, length(h.levels))
tab <- data.frame(h = h.levels, mspe = na, mape = na, obj = na)

st <- Sys.time()
for (idx1 in 1:length(h.levels)) {
	h <- h.levels[idx1]
	y.hat.cv <- rep(NA, n.cv)
	for (k in 1:K) {
		if (verbose) { printf("Fold %d\n", k) }

		# These index into idx.cv
		idx.fold <- folds[[k]]
		idx.notfold <- as.integer(unlist(folds[-k]))

		# These index into the original data
		idx.cv.train <- idx.cv[idx.notfold]
		idx.cv.val <- idx.cv[idx.fold]

		fit.cv <- opg(y[idx.cv.train], X[idx.cv.train,], h = h, d = 1)
		pred.cv <- predict(fit.cv, X.new = X[idx.cv,])
		y.hat.cv[idx.fold] <- pred.cv[idx.fold]
	}
	tab$mape[idx1] <- mean(abs(y[idx.cv] - y.hat.cv))

	if (verbose) {
		printf("h[%d]: %0.4f\n", idx1, h)
		printf("  cv MAPE: %0.4f\n", tab$mape[idx1])
	}
}
printf("Elapsed time of CV: %f sec\n", as.numeric(Sys.time() - st, units = "secs"))
# print(tab)

ggplot(tab, aes(h, mape)) + geom_line(lwd = 1.1)
h.cv <- h.levels[which.min(tab$mape)]

# Check results for best model according to CV
fit.out <- opg(y[idx.cv], X[idx.cv,], h = h.cv, d = 1)
print(fit.out)
pred.out <- predict(fit.out, X.new = X)

ggplot(data.frame(y, pred.out), aes(y, pred.out)) +
    geom_point(color = color) +
    stat_function(fun = identity, lwd = 1.1)

rx <- X %*% fit.out$B
ggplot(data.frame(rx, y), aes(rx, y)) +
    geom_point(color = color) +
    stat_function(fun = f.true, lwd = 1.1)
```

# Bootstrap
Run the bootstrap procedure.
``` {r}
set.seed(1234)
fit.out <- opg(y, X, h = h, d = 1)
pred.out <- predict(fit.out, X.new = X)
rx <- X %*% fit.out$B
print(fit.out)

B <- 500
pred.boot <- matrix(NA, n, B)

st <- Sys.time()
for (b in 1:B) {
	if (verbose) { printf("Computing boostrap iteration %d\n", b) }
	idx.boot <- sample(1:n, size = n, replace = TRUE)
	fit.boot <- opg(y[idx.boot], X[idx.boot,], h = h, d = 1)
	pred.boot[,b] <- predict(fit.boot, X.new = X)
}
printf("Elapsed time of CV: %f sec\n", as.numeric(Sys.time() - st, units = "secs"))

alpha <- 0.05
lo <- apply(pred.boot, 1, quantile, prob = alpha/2)
hi <- apply(pred.boot, 1, quantile, prob = 1 - alpha/2)
dat <- data.frame(rx, yhat = pred.out, lo, hi)
```

Look at some results of the bootstrap.
``` {r}
head(dat)
```
